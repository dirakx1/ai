# Fine tunning LLMS
*  More data and computing, but more exactitude.
*  stop hallucinations, concistence,performance
*  Privacy (on premises, vpc, prevent leakage)
*  Fine tunning and smaller llm can reduce cost for applications that require more requests.
*  Low latency
## Finetuning libs
* Pytorch (meta)
* Huggingface
* LLama library (Lamini)
* The pile. opensource pretrainning data.
* pre-trainning -- base model -- Finetune -- finetune model.
* Finetuning can also have the same kind of unlabeled data  or also labeled or structured data.

# Instruction finetunning

