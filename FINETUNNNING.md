# Fine tunning LLMS
*  more data and computing, but mor exactitude.
*  stop hallucinations, concistence,performance
*  Privacy (on premises, vpc, prevent leakage)
*  Fine tunning and smaller llm can reduce cost for applications that require more requests.
*  Low latency
## Finetuning libs
* Pytorch (meta)
* Huggingface
* LLama library (Lamini) 
